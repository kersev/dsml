---
title: "Basic Statistical Formulae and R code for Data Science"
output: html_document
---

# Basic Statistical Formulas and R Code for Data Science

## Descriptive Statistics

### Mean (Average)

**Summary:** The mean is the sum of all values divided by the number of values,
representing the central tendency of a dataset.

**Formula:** $\bar{x} = \frac{1}{n}\sum_{i=1}^{n}x_i$

**R Code:**

```{r}
# Sample data
x <- c(4, 7, 8, 3, 5, 6)

# Calculate mean
mean(x)

# Handle missing values
mean(x, na.rm = TRUE)
```

### Median

**Summary:** The median is the middle value in a sorted dataset, providing a
measure of central tendency that is robust to outliers.

**Formula:** Middle value of ordered data (or average of two middle values)

**R Code:**

```{r}
# Calculate median
median(x)

# Handle missing values
median(x, na.rm = TRUE)
```

### Mode

**Summary:** The mode is the most frequently occurring value in a dataset,
useful for identifying the most common category or value.

**Formula:** Most frequently occurring value in the dataset

**R Code:**

```{r}
# Mode (not built-in)
get_mode <- function(x) {
  unique_x <- unique(x)
  unique_x[which.max(tabulate(match(x, unique_x)))]
}

get_mode(x)

# Alternative using table
table(x)  # Shows frequency of each value
```

### Variance

**Summary:** Variance measures how far values are spread from the mean, with
larger values indicating greater dispersion.

**Formula:** $\sigma^2 = \frac{1}{n}\sum_{i=1}^{n}(x_i - \bar{x})^2$
(Population) **Formula:** $s^2 = \frac{1}{n-1}\sum_{i=1}^{n}(x_i - \bar{x})^2$
(Sample)

**R Code:**

```{r}
# Sample variance
var(x)

# Population variance
population_var <- function(x) {
  mean((x - mean(x))^2)
}
population_var(x)
```

### Standard Deviation

**Summary:** Standard deviation is the square root of variance, providing a
measure of dispersion in the same units as the original data.

**Formula:** $\sigma = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(x_i - \bar{x})^2}$
(Population) **Formula:**
$s = \sqrt{\frac{1}{n-1}\sum_{i=1}^{n}(x_i - \bar{x})^2}$ (Sample)

**R Code:**

```{r}
# Sample standard deviation
sd(x)

# Population standard deviation
population_sd <- function(x) {
  sqrt(mean((x - mean(x))^2))
}
population_sd(x)
```

### Range

**Summary:** Range is the difference between the maximum and minimum values in a
dataset, providing a simple measure of spread.

**Formula:** max(x) - min(x)

**R Code:**

```{r}
# Calculate range
range_x <- max(x) - min(x)
range_x

# Built-in range function returns min and max
range(x)
```

### Quartiles

**Summary:** Quartiles divide ordered data into four equal parts, helping
understand the distribution of values.

**Formula:** Divides ordered data into four equal parts

**R Code:**

```{r}
# Calculate quartiles
quantile(x)

# Specific quartiles
quantile(x, probs = c(0.25, 0.5, 0.75))
```

### Interquartile Range (IQR)

**Summary:** The IQR is the difference between the third and first quartiles,
representing the middle 50% of the data and useful for identifying outliers.

**Formula:** Q3 - Q1

**R Code:**

```{r}
# Calculate IQR
IQR(x)
```

### Summary Statistics

**Summary:** Summary statistics provide a quick overview of key metrics for a
dataset including measures of central tendency and dispersion.

**R Code:**

```{r}
# Get comprehensive summary
summary(x)

# Custom summary with additional metrics
custom_summary <- function(x) {
  c(mean = mean(x),
    median = median(x),
    sd = sd(x),
    var = var(x),
    min = min(x),
    max = max(x),
    range = max(x) - min(x),
    IQR = IQR(x))
}
custom_summary(x)
```

## Inferential Statistics

### Z-Score (Standard Score)

**Summary:** Z-scores standardize values by expressing them as the number of
standard deviations they are from the mean.

**Formula:** $z = \frac{x - \mu}{\sigma}$

**R Code:**

```{r}
# Calculate z-scores
z_scores <- function(x) {
  (x - mean(x)) / sd(x)
}
z_scores(x)

# Alternative using scale()
scale(x)
```

### Confidence Interval for Mean

**Summary:** Confidence intervals provide a range of values within which the
true population parameter is likely to fall with a specified level of
confidence.

**Formula:** $\bar{x} \pm t_{\alpha/2, n-1} \frac{s}{\sqrt{n}}$

**R Code:**

```{r}
# 95% confidence interval
t.test(x)$conf.int

# Custom confidence interval
conf_int <- function(x, conf_level = 0.95) {
  n <- length(x)
  error <- qt((1 + conf_level) / 2, df = n - 1) * sd(x) / sqrt(n)
  c(lower = mean(x) - error, upper = mean(x) + error)
}
conf_int(x)
```

### Correlation

**Summary:** Correlation measures the strength and direction of the linear
relationship between two variables, ranging from -1 to 1.

**Formula:**
$r = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2 \sum_{i=1}^{n}(y_i - \bar{y})^2}}$

**R Code:**

```{r}
y <- c(2, 6, 7, 1, 3, 5)

# Pearson correlation
cor(x, y)

# Spearman correlation (rank-based)
cor(x, y, method = "spearman")

# Test significance of correlation
cor.test(x, y)
```

### Covariance

**Summary:** Covariance indicates how two variables change together, with
positive values showing they increase together and negative values showing they
move in opposite directions.

**Formula:**
$\text{cov}(x,y) = \frac{1}{n-1}\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})$

**R Code:**

```{r}
# Calculate covariance
cov(x, y)

# Covariance matrix for multiple variables
data <- data.frame(x = x, y = y, z = c(8, 10, 11, 6, 7, 9))
cov(data)
```

## Probability Distributions

### Normal Distribution

**Summary:** The normal distribution is a bell-shaped probability distribution
that is symmetric around its mean and is characterized by its mean and standard
deviation.

**R Code:**

```{r}
# Generate normal random variables
rnorm(100, mean = 0, sd = 1)

# Calculate normal density
x_vals <- seq(-3, 3, by = 0.1)
plot(x_vals, dnorm(x_vals), type = "l", main = "Normal Distribution")

# Calculate normal cumulative probability
pnorm(1.96)  # P(Z < 1.96)

# Calculate normal quantile
qnorm(0.975)  # Value at which P(Z < q) = 0.975
```

### Binomial Distribution

**Summary:** The binomial distribution models the number of successes in a fixed
number of independent trials, each with the same probability of success.

**R Code:**

```{r}
# Generate binomial random values
rbinom(100, size = 10, prob = 0.5)

# Calculate binomial probability
dbinom(7, size = 10, prob = 0.5)  # P(X = 7)

# Calculate binomial cumulative probability
pbinom(7, size = 10, prob = 0.5)  # P(X ≤ 7)
```

### Poisson Distribution

**Summary:** The Poisson distribution models the number of events occurring in a
fixed time interval or space when events happen at a constant rate and
independently of each other.

**R Code:**

```{r}
# Generate Poisson random values
rpois(100, lambda = 3)

# Calculate Poisson probability
dpois(5, lambda = 3)  # P(X = 5)

# Calculate Poisson cumulative probability
ppois(5, lambda = 3)  # P(X ≤ 5)
```

## Hypothesis Testing

### t-test

**Summary:** The t-test compares means of one or two groups to determine if they
are significantly different from each other or from a reference value.

**R Code:**

```{r}
# One-sample t-test
t.test(x, mu = 5)

# Two-sample t-test
t.test(x, y)

# Paired t-test
t.test(x, y, paired = TRUE)
```

### ANOVA

**Summary:** Analysis of Variance (ANOVA) compares means across three or more
groups to determine if at least one group mean is significantly different from
the others.

**R Code:**

```{r}
# Create groups
groups <- factor(rep(letters[1:3], each = 2))
values <- c(x[1:2], y[1:2], c(8, 9))

# One-way ANOVA
model <- aov(values ~ groups)
summary(model)
```

### Chi-square Test

**Summary:** The Chi-square test determines whether there is a significant
association between categorical variables or if observed frequencies differ from
expected frequencies.

**R Code:**

```{r}
# Contingency table
observed <- matrix(c(20, 10, 15, 25), nrow = 2)

# Chi-Square Test
chisq.test(observed)
```

## Regression Analysis

### Simple Linear Regression

**Summary:** Simple linear regression models the relationship between a
dependent variable and a single independent variable using a linear equation.

**Formula:** $y = \beta_0 + \beta_1 x + \epsilon$

**R Code:**

```{r}
# Fit linear model
model <- lm(y ~ x)
summary(model)

# Get coefficients
coef(model)

# Make predictions
predict(model, data.frame(x = c(5, 10)))

# Plot regression line
plot(x, y)
abline(model, col = "red")
```

### Multiple Linear Regression

**Summary:** Multiple linear regression extends simple linear regression by
modeling the relationship between a dependent variable and multiple independent
variables.

**Formula:**
$y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_p x_p + \epsilon$

**R Code:**

```{r}
# Sample data
z <- c(1, 3, 2, 4, 5, 6)
df <- data.frame(y = y, x1 = x, x2 = z)

# Fit multiple regression
model <- lm(y ~ x1 + x2, data = df)
summary(model)

# Predictions
new_data <- data.frame(x1 = c(5, 6), x2 = c(3, 4))
predict(model, new_data)
```
